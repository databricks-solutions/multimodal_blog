{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0130240a-57eb-499b-b139-301a1d287c66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq databricks-sdk[openai] databricks-vectorsearch mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1ad4496-8057-448f-adc0-cb49f1e9d457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PyFunc Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1377ce92-63a0-4c31-92c2-0034e0c5796e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile CarDamageClassifier.py\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models import set_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "from typing import List, Literal, Any, Dict, Optional\n",
    "from pydantic import BaseModel\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "import base64\n",
    "from copy import deepcopy\n",
    "\n",
    "# Pydantic models for damage classification\n",
    "class DamageType(BaseModel):\n",
    "    part: Literal[\n",
    "        \"Front Bumper\",\n",
    "        \"Rear Bumper\",\n",
    "        \"Fender\",\n",
    "        \"Hood\",\n",
    "        \"Trunk Lid\",\n",
    "        \"Roof Panel\",\n",
    "        \"Door Panel\",\n",
    "        \"Quarter Panel\",\n",
    "        \"Windshield\",\n",
    "        \"Side Window\",\n",
    "        \"Rear Window\",\n",
    "        \"Headlamp\",\n",
    "        \"Tail Lamp\",\n",
    "        \"Unknown\"\n",
    "    ]\n",
    "\n",
    "class DamageAnalysis(BaseModel):\n",
    "    is_damaged: bool\n",
    "    damage_list: List[DamageType]\n",
    "\n",
    "\n",
    "class CarDamageClassifier(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the model. Clients will be initialized in load_context.\n",
    "        \"\"\"\n",
    "        self.deploy_client = None\n",
    "        self.vector_search_client = None\n",
    "        self.vector_index = None\n",
    "        \n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        Load the model context and initialize clients.\n",
    "        This is called once when the model is loaded.\n",
    "        \"\"\"\n",
    "        import mlflow.deployments\n",
    "        from databricks.vector_search.client import VectorSearchClient\n",
    "        \n",
    "        # Initialize deployment client for accessing endpoints\n",
    "        # This will use the environment's authentication automatically\n",
    "        self.deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "        \n",
    "        # Initialize Vector Search Client\n",
    "        # This will also use the environment's authentication\n",
    "        self.vector_search_client = VectorSearchClient()\n",
    "        \n",
    "        # Get the vector search index\n",
    "        try:\n",
    "            self.vector_index = self.vector_search_client.get_index(\n",
    "                endpoint_name=\"multi_modal_blog_endpoint\",\n",
    "                index_name=\"users.colton_peltier.classified_damages_gold_index\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize vector index: {e}\")\n",
    "            self.vector_index = None\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_process_image\", span_type=\"PARSER\")\n",
    "    def resize_single_image(self, content: bytes) -> bytes:\n",
    "        \"\"\"Resize a single image to max dimension of 336px while maintaining aspect ratio\"\"\"\n",
    "        buffer = io.BytesIO()\n",
    "        max_side = 336\n",
    "        img = Image.open(io.BytesIO(content))\n",
    "        img.thumbnail((max_side, max_side))\n",
    "        img.save(buffer, format=\"JPEG\")\n",
    "        return buffer.getvalue()\n",
    "    \n",
    "    def recursive_schema_flatten(self, schema: Any, refs_dict: dict) -> dict:\n",
    "        \"\"\"Recursively flatten schema references\"\"\"\n",
    "        if isinstance(schema, dict):\n",
    "            if \"$ref\" in schema:\n",
    "                ref = schema[\"$ref\"]\n",
    "                reference_name = ref.split(\"/\")[-1]\n",
    "                return self.recursive_schema_flatten(refs_dict[reference_name], refs_dict)\n",
    "            return {k: self.recursive_schema_flatten(v, refs_dict) for k, v in schema.items()}\n",
    "        if isinstance(schema, list):\n",
    "            return [self.recursive_schema_flatten(v, refs_dict) for v in schema]\n",
    "        return schema\n",
    "\n",
    "    def pydantic_to_ai_query_json_schema(self, pydantic_model: BaseModel, name: str, strict: bool) -> dict:\n",
    "        \"\"\"Convert Pydantic model to flattened JSON schema for AI query\"\"\"\n",
    "        _model = deepcopy(pydantic_model)\n",
    "        model_schema = _model.model_json_schema()\n",
    "        refs = model_schema.get(\"$defs\", {})\n",
    "        # Delete the refs from the schema\n",
    "        model_schema.pop(\"$defs\", None)\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"schema\": self.recursive_schema_flatten(model_schema, refs),\n",
    "            \"strict\": strict\n",
    "        }\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_create_prompt\", span_type=\"PARSER\")\n",
    "    def _create_prompt(self, image_base64: str) -> dict:\n",
    "        \"\"\"Create the prompt for Llama 4 Maverick with structured output requirements\"\"\"\n",
    "        \n",
    "        # Generate the flattened schema for the response format\n",
    "        response_schema = self.pydantic_to_ai_query_json_schema(\n",
    "            DamageAnalysis,\n",
    "            name=\"damage_analysis\",\n",
    "            strict=True\n",
    "        )\n",
    "        \n",
    "        # Create a human-readable description of the schema for the system prompt\n",
    "        schema_description = json.dumps(response_schema[\"schema\"], indent=2)\n",
    "        \n",
    "        system_prompt = f\"\"\"You are an expert mechanic working at a body repair shop. Your job is to look at an image and accurately list any body panels which are damaged on the car in the image. If multiple of the same part are damaged (like 2 doors) list that part mulitple times. If the part is unknown, choose Unknown.\\n\\nYou must respond with a JSON object that strictly follows this schema: {schema_description}\"\"\"\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Please analyze this car image for damage and provide a structured assessment following the specified JSON schema.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 500,\n",
    "            \"temperature\": 0.1,  # Low temperature for consistent classification\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": response_schema\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_call_llm\", span_type=\"CHAT_MODEL\")\n",
    "    def _call_llama_api(self, image_bytes: bytes) -> DamageAnalysis:\n",
    "        \"\"\"Call Databricks-hosted Llama 4 Maverick API via Foundation Models\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Convert image to base64 for API transmission\n",
    "            image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "            \n",
    "            # Create the request payload using the same prompt structure\n",
    "            payload = self._create_prompt(image_base64)\n",
    "            \n",
    "            # Call the model using MLflow deployments client\n",
    "            response = self.deploy_client.predict(\n",
    "                endpoint=\"databricks-llama-4-maverick\",\n",
    "                inputs=payload\n",
    "            )\n",
    "            \n",
    "            # Extract the JSON from the model's response\n",
    "            if isinstance(response, dict):\n",
    "                if \"choices\" in response:\n",
    "                    content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                else:\n",
    "                    content = response.get(\"predictions\", [{}])[0].get(\"content\", \"{}\")\n",
    "            else:\n",
    "                content = str(response)\n",
    "            \n",
    "            # Parse the JSON response into our Pydantic model\n",
    "            damage_data = json.loads(content)\n",
    "            \n",
    "            # Validate with Pydantic\n",
    "            analysis = DamageAnalysis(**damage_data)\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in _call_llama_api: {type(e).__name__}: {str(e)}\")\n",
    "            return DamageAnalysis(is_damaged=False, damage_list=[])\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_get_embeddings\", span_type=\"EMBEDDING\")\n",
    "    def _get_damage_embeddings(self, damaged_parts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get embeddings for the damaged parts list using the embeddings endpoint.\n",
    "        Sums embeddings for multiple damage parts.\n",
    "        \"\"\"\n",
    "        # Check if damaged_parts is empty or None\n",
    "        if not damaged_parts:\n",
    "            return np.zeros(1024)\n",
    "        \n",
    "        try:\n",
    "            embeddings_list = []\n",
    "            \n",
    "            # Get embeddings for each damage part and sum them\n",
    "            for part in damaged_parts:\n",
    "                try:\n",
    "                    # Use the deployments client to get embeddings\n",
    "                    response = self.deploy_client.predict(\n",
    "                        endpoint=\"databricks-gte-large-en\",\n",
    "                        inputs={\"input\": part}\n",
    "                    )\n",
    "                    \n",
    "                    # Extract embedding from response\n",
    "                    if isinstance(response, dict):\n",
    "                        if \"data\" in response and response[\"data\"]:\n",
    "                            embedding = np.array(response[\"data\"][0][\"embedding\"])\n",
    "                            embeddings_list.append(embedding)\n",
    "                        elif \"embeddings\" in response:\n",
    "                            embedding = np.array(response[\"embeddings\"][0])\n",
    "                            embeddings_list.append(embedding)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error getting embedding for part '{part}': {type(e).__name__}: {str(e)}\")\n",
    "            \n",
    "            # Sum all embeddings\n",
    "            if embeddings_list:\n",
    "                return_embeddings = np.sum(embeddings_list, axis=0)\n",
    "                return return_embeddings\n",
    "            else:\n",
    "                # Return zero vector if no embeddings were successfully retrieved\n",
    "                return np.zeros(1024)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in _get_damage_embeddings: {type(e).__name__}: {str(e)}\")\n",
    "            # Return zero vector on any fatal error\n",
    "            return np.zeros(1024)\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_vector_search\", span_type=\"RETRIEVER\")\n",
    "    def _find_similar_claims(self, damaged_parts: List[str]) -> dict:\n",
    "        \"\"\"\n",
    "        Find similar claims using vector search and calculate estimated quote.\n",
    "        \"\"\"\n",
    "        if not self.vector_index:\n",
    "            print(\"Vector index not available, skipping similarity search\")\n",
    "            return {\n",
    "                'estimated_quote': 0.0,\n",
    "                'similar_claim_ids': [],\n",
    "                'similar_claims_count': 0,\n",
    "                'similar_claims_details': []\n",
    "            }\n",
    "            \n",
    "        try:\n",
    "            # Get embeddings for the damaged parts\n",
    "            damage_embeddings = self._get_damage_embeddings(damaged_parts)\n",
    "            \n",
    "            # Perform similarity search using the loaded vector index\n",
    "            results = self.vector_index.similarity_search(\n",
    "                query_vector=damage_embeddings.tolist(),\n",
    "                columns=[\"damage_list\", \"claim_id\", \"final_cost_to_customer\"],\n",
    "                num_results=5\n",
    "            )\n",
    "            \n",
    "            # Extract similar claims data\n",
    "            similar_claims = []\n",
    "            total_cost = 0.0\n",
    "            claim_ids = []\n",
    "            \n",
    "            if results and 'result' in results and 'data_array' in results['result']:\n",
    "                for claim_data in results['result']['data_array']:\n",
    "                    damage_list, claim_id, cost, score = claim_data\n",
    "                    similar_claims.append({\n",
    "                        'damage_list': damage_list,\n",
    "                        'claim_id': claim_id,\n",
    "                        'cost': cost,\n",
    "                        'similarity_score': score\n",
    "                    })\n",
    "                    total_cost += cost\n",
    "                    claim_ids.append(claim_id)\n",
    "                \n",
    "                # Calculate average cost\n",
    "                avg_cost = total_cost / len(similar_claims) if similar_claims else 0.0\n",
    "                \n",
    "                return {\n",
    "                    'estimated_quote': round(avg_cost, 2),\n",
    "                    'similar_claim_ids': claim_ids,\n",
    "                    'similar_claims_count': len(similar_claims),\n",
    "                    'similar_claims_details': similar_claims\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'estimated_quote': 0.0,\n",
    "                    'similar_claim_ids': [],\n",
    "                    'similar_claims_count': 0,\n",
    "                    'similar_claims_details': []\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in vector search: {str(e)}\")\n",
    "            return {\n",
    "                'estimated_quote': 0.0,\n",
    "                'similar_claim_ids': [],\n",
    "                'similar_claims_count': 0,\n",
    "                'similar_claims_details': [],\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    @mlflow.trace(name=\"car_damage_classification_predict\", span_type=\"AGENT\")\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"\n",
    "        Process car images for damage detection and estimate repair costs.\n",
    "        \n",
    "        Args:\n",
    "            context: MLflow PythonModelContext (contains artifacts path, etc.)\n",
    "            model_input: pandas DataFrame with 'image' column containing image bytes\n",
    "            params: Optional parameters dictionary\n",
    "            \n",
    "        Returns:\n",
    "            pandas DataFrame with damage classification and cost estimation results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Process each image\n",
    "        for idx, row in model_input.iterrows():\n",
    "            try:\n",
    "                # Get image bytes from the row\n",
    "                image_bytes = row['image']\n",
    "                \n",
    "                # Resize the image\n",
    "                resized_image = self.resize_single_image(image_bytes)\n",
    "                \n",
    "                # Call Llama API for classification\n",
    "                analysis = self._call_llama_api(resized_image)\n",
    "                \n",
    "                # Format results for output\n",
    "                damage_parts = [damage.part for damage in analysis.damage_list]\n",
    "                \n",
    "                # Initialize result dictionary\n",
    "                result = {\n",
    "                    'is_damaged': analysis.is_damaged,\n",
    "                    'damage_count': len(analysis.damage_list),\n",
    "                    'damaged_parts': json.dumps(damage_parts),  # Convert to JSON string\n",
    "                    'damage_details': analysis.model_dump_json(),\n",
    "                    'estimated_quote': 0.0,\n",
    "                    'similar_claim_ids': json.dumps([]),  # Convert to JSON string\n",
    "                    'similar_claims_count': 0\n",
    "                }\n",
    "                \n",
    "                # If damage is detected, find similar claims and estimate cost\n",
    "                if analysis.is_damaged and damage_parts:\n",
    "                    similarity_results = self._find_similar_claims(damage_parts)\n",
    "                    result.update({\n",
    "                        'estimated_quote': similarity_results['estimated_quote'],\n",
    "                        'similar_claim_ids': json.dumps(similarity_results['similar_claim_ids']),\n",
    "                        'similar_claims_count': similarity_results['similar_claims_count']\n",
    "                    })\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Handle any unexpected errors\n",
    "                print(f\"Error processing image at index {idx}: {str(e)}\")\n",
    "                results.append({\n",
    "                    'is_damaged': False,\n",
    "                    'damage_count': 0,\n",
    "                    'damaged_parts': json.dumps([]),\n",
    "                    'damage_details': json.dumps({\"error\": str(e)}),\n",
    "                    'estimated_quote': 0.0,\n",
    "                    'similar_claim_ids': json.dumps([]),\n",
    "                    'similar_claims_count': 0\n",
    "                })\n",
    "        \n",
    "        # Convert results to DataFrame to match the output schema\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Set the model for serving\n",
    "set_model(CarDamageClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8766efc0-f27b-4490-bd68-ab2f2ec0e794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Input Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "872125d8-1150-4762-822b-96d99aba9160",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "import json\n",
    "from pyspark.sql import functions as F\n",
    "from copy import deepcopy\n",
    "import io\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "import json\n",
    "\n",
    "def resize_single_image(content : bytes) -> bytes:\n",
    "  buffer = io.BytesIO()\n",
    "  max_side = 336\n",
    "  img = Image.open(io.BytesIO(content))\n",
    "  img.thumbnail((max_side, max_side))\n",
    "  img.save(buffer, format=\"JPEG\")\n",
    "  return buffer.getvalue()\n",
    "\n",
    "@F.pandas_udf(\"binary\")\n",
    "def resize_image(content : pd.Series) -> pd.Series:\n",
    "  return content.apply(resize_single_image)\n",
    "\n",
    "my_files = (\n",
    "  spark\n",
    "  .read\n",
    "  .format(\"binaryFile\")\n",
    "  .load(f\"/Volumes/users/colton_peltier/car_damage_raw_images/kaggle/raw_images/images/\")\n",
    "  .limit(10)\n",
    "  .withColumn(\"resized_image\", resize_image(F.col(\"content\")))\n",
    ").collect()[9][\"resized_image\"]\n",
    "\n",
    "input_example = pd.DataFrame({\"image\": [my_files]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93025afb-4032-491c-8519-5c1a82f9ee81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4b874ab-8f0d-4c3c-bb4d-bf93905b93be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First we need to establish the MLflow experiment, pip requirements, signature and other elements for logging the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "381c31c8-7300-455f-bc53-bfd0e234b599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksServingEndpoint, \n",
    "    DatabricksVectorSearchIndex\n",
    ")\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "\n",
    "\n",
    "# Create sample input for signature\n",
    "sample_input = pd.DataFrame({\n",
    "    'image': [b'sample_image_bytes']  # Replace with actual image bytes in production\n",
    "})\n",
    "\n",
    "# Define the output schema\n",
    "output_schema = Schema([\n",
    "    ColSpec(\"boolean\", \"is_damaged\"),\n",
    "    ColSpec(\"integer\", \"damage_count\"),\n",
    "    ColSpec(\"string\", \"damaged_parts\"), \n",
    "    ColSpec(\"string\", \"damage_details\"),\n",
    "    ColSpec(\"double\", \"estimated_quote\"), \n",
    "    ColSpec(\"string\", \"similar_claim_ids\"),  \n",
    "    ColSpec(\"integer\", \"similar_claims_count\") \n",
    "])\n",
    "\n",
    "# Create signature\n",
    "signature = ModelSignature(\n",
    "    inputs=Schema([ColSpec(\"binary\", \"image\")]),\n",
    "    outputs=output_schema\n",
    ")\n",
    "\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint, DatabricksVectorSearchIndex\n",
    "# Define the resources that will be used by the model\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=\"databricks-llama-4-maverick\"),\n",
    "    DatabricksServingEndpoint(endpoint_name=\"databricks-gte-large-en\"),\n",
    "    DatabricksVectorSearchIndex(index_name=\"users.colton_peltier.classified_damages_gold_index\")\n",
    "]\n",
    "\n",
    "# Log the model with resources\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"car_damage_classifier\",\n",
    "        python_model=\"CarDamageClassifier.py\",\n",
    "        resources=resources,\n",
    "        signature=signature,\n",
    "        input_example=sample_input,\n",
    "        pip_requirements=[\n",
    "            \"mlflow>=2.15.0\",\n",
    "            \"pydantic>=2.0.0\",\n",
    "            \"pillow>=10.0.0\",\n",
    "            \"numpy>=1.24.0\",\n",
    "            \"pandas>=2.0.0\",\n",
    "            \"databricks-vectorsearch\",\n",
    "            \"openai\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"Model logged successfully with resources!\")\n",
    "    print(mlflow.active_run().info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad0b5b20-07b3-4bdb-b2ff-4369c33210eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Final Validation Prior to Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067335db-7b11-4142-a9b5-2bc93cefba72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logged_agent_info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "513f6e8b-b3ba-4081-81fe-333c3bcae2d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/car_damage_classifier\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef2be98-cbe3-4991-84cf-39776e4daa16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"users\"\n",
    "schema = \"colton_peltier\"\n",
    "model_name = \"car_damage_classifier\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "385b4c22-5e58-4897-b52c-fb716f2fd056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the Deployed Model from the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93632e96-c6ac-4525-9b28-9016fb531e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "host = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "def score_model_debug(dataset):\n",
    "    url = f'{host}/serving-endpoints/car_damage_classifier/invocations'\n",
    "    headers = {'Authorization': f'Bearer {token}', 'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Debug: Check input\n",
    "    print(f\"[DEBUG] Input DataFrame shape: {dataset.shape}\")\n",
    "    print(f\"[DEBUG] Input DataFrame columns: {dataset.columns.tolist()}\")\n",
    "    \n",
    "    # Check the actual data type\n",
    "    sample = dataset['image'].iloc[0]\n",
    "    print(f\"[DEBUG] Sample image type: {type(sample)}\")\n",
    "    print(f\"[DEBUG] Sample image length: {len(sample) if hasattr(sample, '__len__') else 'N/A'}\")\n",
    "    \n",
    "    # Convert bytearray to base64\n",
    "    records = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        image_data = row['image']\n",
    "        \n",
    "        if isinstance(image_data, bytearray):\n",
    "            image_bytes = bytes(image_data)\n",
    "        elif isinstance(image_data, bytes):\n",
    "            image_bytes = image_data\n",
    "        else:\n",
    "            print(f\"[WARNING] Unexpected type: {type(image_data)}\")\n",
    "            image_bytes = image_data\n",
    "        \n",
    "        base64_str = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        print(f\"[DEBUG] Base64 length for image {idx}: {len(base64_str)}\")\n",
    "        print(f\"[DEBUG] Base64 preview: {base64_str[:100]}...\")\n",
    "        \n",
    "        records.append({\"image\": base64_str})\n",
    "    \n",
    "    # Try different payload formats\n",
    "    payloads = [\n",
    "        # Format 1: dataframe_records\n",
    "        (\"dataframe_records\", {\"dataframe_records\": records}),\n",
    "        \n",
    "        # Format 2: instances\n",
    "        (\"instances\", {\"instances\": records}),\n",
    "        \n",
    "        # Format 3: dataframe_split with explicit columns\n",
    "        (\"dataframe_split\", {\n",
    "            \"dataframe_split\": {\n",
    "                \"columns\": [\"image\"],\n",
    "                \"data\": [[r[\"image\"]] for r in records]\n",
    "            }\n",
    "        }),\n",
    "        \n",
    "        # Format 4: inputs (some endpoints use this)\n",
    "        (\"inputs\", {\"inputs\": records})\n",
    "    ]\n",
    "    \n",
    "    for format_name, payload in payloads:\n",
    "        print(f\"\\n[DEBUG] Trying format: {format_name}\")\n",
    "        data_json = json.dumps(payload)\n",
    "        print(f\"[DEBUG] Payload size: {len(data_json)} bytes\")\n",
    "        \n",
    "        response = requests.post(url, headers=headers, data=data_json)\n",
    "        print(f\"[DEBUG] Response status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"[DEBUG] Success with format: {format_name}\")\n",
    "            print(f\"[DEBUG] Response: {json.dumps(result, indent=2)}\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"[DEBUG] Failed with {format_name}: {response.text[:200]}\")\n",
    "    \n",
    "    raise Exception(\"All formats failed\")\n",
    "\n",
    "# Test it\n",
    "result = score_model_debug(input_example)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_65bc13ea-276c-4905-a728-9fe2fb1780e2",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "CarDamageClassifier_Pyfunc",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}